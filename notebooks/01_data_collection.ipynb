{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cc9c36-6d3d-4bc1-9d57-136ce590bb1f",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Setup and Imports\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10293d5c-f84b-439f-919e-53e3a2f2a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - ready to collect e-commerce data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducible results\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "\n",
    "# Create project directories\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "print(\"Setup complete - ready to collect e-commerce data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb744756-2134-4a46-bad0-a8a93f124e95",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Product Category Templates\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c025b731-8349-45ac-8cc0-604a64717a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product templates ready for 4 categories\n"
     ]
    }
   ],
   "source": [
    "# Realistic product categories with brands and price ranges\n",
    "PRODUCT_CATEGORIES = {\n",
    "    \"electronics\": {\n",
    "        \"types\": [\"smartphones\", \"laptops\", \"tablets\", \"headphones\", \"cameras\", \"speakers\"],\n",
    "        \"brands\": [\"Apple\", \"Samsung\", \"Sony\", \"Dell\", \"HP\", \"Canon\", \"Bose\", \"JBL\"],\n",
    "        \"price_range\": (50, 2000),\n",
    "        \"popularity_factor\": 1.5  # Electronics get more reviews\n",
    "    },\n",
    "    \"jewelery\": {\n",
    "        \"types\": [\"rings\", \"necklaces\", \"earrings\", \"bracelets\", \"watches\", \"chains\"],\n",
    "        \"brands\": [\"Tiffany\", \"Cartier\", \"Pandora\", \"Swarovski\", \"Kay\", \"Zales\"],\n",
    "        \"price_range\": (25, 1000),\n",
    "        \"popularity_factor\": 0.8\n",
    "    },\n",
    "    \"men's clothing\": {\n",
    "        \"types\": [\"shirts\", \"pants\", \"jackets\", \"shoes\", \"accessories\", \"activewear\"],\n",
    "        \"brands\": [\"Nike\", \"Adidas\", \"Levi's\", \"Ralph Lauren\", \"Calvin Klein\", \"Under Armour\"],\n",
    "        \"price_range\": (15, 400),\n",
    "        \"popularity_factor\": 1.0\n",
    "    },\n",
    "    \"women's clothing\": {\n",
    "        \"types\": [\"dresses\", \"tops\", \"pants\", \"shoes\", \"bags\", \"accessories\"],\n",
    "        \"brands\": [\"Zara\", \"H&M\", \"Kate Spade\", \"Michael Kors\", \"Lululemon\", \"Anthropologie\"],\n",
    "        \"price_range\": (20, 500),\n",
    "        \"popularity_factor\": 1.3\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Product templates ready for {len(PRODUCT_CATEGORIES)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aaa546-78bc-4af8-9fe0-70e889631ba6",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 3: API Data Collection\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f374f2-b14f-416c-a69b-3378d5072140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 template products from API\n",
      "API data overview:\n",
      "  Categories: [\"women's clothing\", 'electronics', 'jewelery', \"men's clothing\"]\n",
      "  Price range: $7.95 - $999.99\n",
      "  Ready to expand dataset\n"
     ]
    }
   ],
   "source": [
    "def fetch_base_products():\n",
    "    \"\"\"Get sample products from Fake Store API as templates\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://fakestoreapi.com/products\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            products = response.json()\n",
    "            print(f\"Fetched {len(products)} template products from API\")\n",
    "            return products\n",
    "        else:\n",
    "            print(f\"API request failed with status {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching from API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get base products\n",
    "base_products = fetch_base_products()\n",
    "\n",
    "if base_products:\n",
    "    # Quick analysis\n",
    "    categories = [p['category'] for p in base_products]\n",
    "    prices = [p['price'] for p in base_products]\n",
    "    \n",
    "    print(f\"API data overview:\")\n",
    "    print(f\"  Categories: {list(set(categories))}\")\n",
    "    print(f\"  Price range: ${min(prices):.2f} - ${max(prices):.2f}\")\n",
    "    print(f\"  Ready to expand dataset\")\n",
    "else:\n",
    "    print(\"Could not fetch base products - will use fallback generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f248545-242c-47c0-b74d-5b47b461f644",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Product Generation Functions\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258de4ea-7653-4374-a9bb-f96a519366c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting product generation...\n",
      "Generating 2000 realistic products...\n",
      "  Creating 500 electronics products...\n",
      "  Creating 500 jewelery products...\n",
      "  Creating 500 men's clothing products...\n",
      "  Creating 500 women's clothing products...\n",
      "Generated 2000 total products\n",
      "\n",
      "Dataset summary:\n",
      "  Total products: 2000\n",
      "  Price range: $13.58 - $2708.43\n",
      "  Rating range: 1.0 - 5.0\n",
      "  women's clothing: 500 products\n",
      "  electronics: 500 products\n",
      "  jewelery: 500 products\n",
      "  men's clothing: 500 products\n"
     ]
    }
   ],
   "source": [
    "def generate_realistic_product(category, product_id, base_template=None):\n",
    "    \"\"\"Generate a single realistic product for the category\"\"\"\n",
    "    \n",
    "    category_data = PRODUCT_CATEGORIES[category]\n",
    "    \n",
    "    # Select random attributes\n",
    "    product_type = random.choice(category_data[\"types\"])\n",
    "    brand = random.choice(category_data[\"brands\"])\n",
    "    \n",
    "    # Generate realistic price\n",
    "    min_price, max_price = category_data[\"price_range\"]\n",
    "    base_price = random.uniform(min_price, max_price)\n",
    "    \n",
    "    # Add some price variation (market inefficiencies)\n",
    "    if random.random() < 0.05:  # 5% get unusual pricing\n",
    "        if random.random() < 0.5:\n",
    "            base_price *= random.uniform(1.5, 2.0)  # Overpriced\n",
    "        else:\n",
    "            base_price *= random.uniform(0.5, 0.8)  # Underpriced gems\n",
    "    \n",
    "    price = round(base_price, 2)\n",
    "    \n",
    "    # Generate rating with realistic distribution\n",
    "    # Higher prices get slight rating boost, but with variation\n",
    "    price_factor = (price - min_price) / (max_price - min_price)\n",
    "    base_rating = random.normalvariate(4.0, 0.8)\n",
    "    rating = max(1.0, min(5.0, base_rating + price_factor * 0.3))\n",
    "    rating = round(rating, 1)\n",
    "    \n",
    "    # Generate review count based on rating and category popularity\n",
    "    popularity = category_data[\"popularity_factor\"]\n",
    "    rating_boost = (rating - 1) / 4  # 0-1 scale\n",
    "    base_reviews = random.lognormvariate(4, 1.2)\n",
    "    review_count = max(5, int(base_reviews * popularity * (1 + rating_boost)))\n",
    "    \n",
    "    # Create product title and description\n",
    "    title = f\"{brand} {product_type.title()} - {fake.catch_phrase()}\"\n",
    "    description = f\"Quality {product_type} from {brand}. {fake.text(max_nb_chars=150)}\"\n",
    "    \n",
    "    # Use base template image if available\n",
    "    image_url = \"https://via.placeholder.com/300\"\n",
    "    if base_template and 'image' in base_template:\n",
    "        image_url = base_template['image']\n",
    "    \n",
    "    return {\n",
    "        \"id\": product_id,\n",
    "        \"title\": title,\n",
    "        \"price\": price,\n",
    "        \"description\": description,\n",
    "        \"category\": category,\n",
    "        \"image\": image_url,\n",
    "        \"rating\": {\n",
    "            \"rate\": rating,\n",
    "            \"count\": review_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "def create_product_dataset(target_size=2000):\n",
    "    \"\"\"Generate a large, realistic product dataset\"\"\"\n",
    "    \n",
    "    print(f\"Generating {target_size} realistic products...\")\n",
    "    \n",
    "    products = []\n",
    "    products_per_category = target_size // len(PRODUCT_CATEGORIES)\n",
    "    \n",
    "    for category in PRODUCT_CATEGORIES.keys():\n",
    "        print(f\"  Creating {products_per_category} {category} products...\")\n",
    "        \n",
    "        # Find base template for this category\n",
    "        base_template = None\n",
    "        if base_products:\n",
    "            category_templates = [p for p in base_products if p['category'].lower() == category.lower()]\n",
    "            if category_templates:\n",
    "                base_template = random.choice(category_templates)\n",
    "        \n",
    "        # Generate products for this category\n",
    "        for i in range(products_per_category):\n",
    "            product_id = len(products) + 1000  # Start IDs from 1000\n",
    "            product = generate_realistic_product(category, product_id, base_template)\n",
    "            products.append(product)\n",
    "    \n",
    "    print(f\"Generated {len(products)} total products\")\n",
    "    return products\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Starting product generation...\")\n",
    "large_dataset = create_product_dataset(2000)\n",
    "\n",
    "# Quick validation\n",
    "if large_dataset:\n",
    "    categories = [p['category'] for p in large_dataset]\n",
    "    prices = [p['price'] for p in large_dataset]\n",
    "    ratings = [p['rating']['rate'] for p in large_dataset]\n",
    "    \n",
    "    print(f\"\\nDataset summary:\")\n",
    "    print(f\"  Total products: {len(large_dataset)}\")\n",
    "    print(f\"  Price range: ${min(prices):.2f} - ${max(prices):.2f}\")\n",
    "    print(f\"  Rating range: {min(ratings):.1f} - {max(ratings):.1f}\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    for category in set(categories):\n",
    "        count = categories.count(category)\n",
    "        print(f\"  {category}: {count} products\")\n",
    "else:\n",
    "    print(\"Product generation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26386f7a-a6aa-4658-81b3-d8aa87d0ca72",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Create Enhanced DataFrame\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9d4c6f-c19f-40aa-b40a-dbcf1ef5ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2000 products into business DataFrame...\n",
      "Adding business metrics...\n",
      "\n",
      "Enhanced DataFrame created:\n",
      "  Shape: (2000, 14)\n",
      "  Columns: ['id', 'title', 'price', 'description', 'category', 'image', 'rating_score', 'rating_count', 'value_score', 'popularity_score', 'performance_category', 'revenue_potential', 'title_length', 'description_length']\n",
      "\n",
      "Performance categories:\n",
      "  Premium Star: 505 (25.2%)\n",
      "  Budget Basic: 501 (25.1%)\n",
      "  Value Champion: 499 (24.9%)\n",
      "  Overpriced: 495 (24.8%)\n",
      "\n",
      "Top 5 value champions:\n",
      "  Cartier Earrings - Configurable responsi... - $14.21 - 5.0/5\n",
      "  Nike Shirts - Programmable homogeneous d... - $13.58 - 4.4/5\n",
      "  Under Armour Accessories - Cloned upward... - $15.28 - 4.7/5\n",
      "  Ralph Lauren Jackets - Ergonomic asymmet... - $21.74 - 4.5/5\n",
      "  Ralph Lauren Activewear - Profit-focused... - $22.91 - 4.7/5\n"
     ]
    }
   ],
   "source": [
    "def create_business_dataframe(products_data):\n",
    "    \"\"\"Convert product data to DataFrame with business metrics\"\"\"\n",
    "    \n",
    "    if not products_data:\n",
    "        print(\"No product data to process\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing {len(products_data)} products into business DataFrame...\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(products_data)\n",
    "    \n",
    "    # Extract rating components\n",
    "    if 'rating' in df.columns:\n",
    "        df['rating_score'] = df['rating'].apply(lambda x: x['rate'])\n",
    "        df['rating_count'] = df['rating'].apply(lambda x: x['count'])\n",
    "        df = df.drop('rating', axis=1)\n",
    "    \n",
    "    # Add business intelligence features\n",
    "    print(\"Adding business metrics...\")\n",
    "    \n",
    "    # Value score - rating quality per dollar spent\n",
    "    df['value_score'] = df['rating_score'] / (df['price'] / 100)\n",
    "    \n",
    "    # Popularity score - normalized review volume\n",
    "    df['popularity_score'] = df['rating_count'] / df['rating_count'].max()\n",
    "    \n",
    "    # Performance categories (simple 2x2 matrix)\n",
    "    price_median = df['price'].median()\n",
    "    rating_median = df['rating_score'].median()\n",
    "    \n",
    "    def categorize_performance(row):\n",
    "        high_price = row['price'] >= price_median\n",
    "        high_rating = row['rating_score'] >= rating_median\n",
    "        \n",
    "        if high_price and high_rating:\n",
    "            return 'Premium Star'\n",
    "        elif not high_price and high_rating:\n",
    "            return 'Value Champion'\n",
    "        elif high_price and not high_rating:\n",
    "            return 'Overpriced'\n",
    "        else:\n",
    "            return 'Budget Basic'\n",
    "    \n",
    "    df['performance_category'] = df.apply(categorize_performance, axis=1)\n",
    "    \n",
    "    # Revenue potential estimate\n",
    "    df['revenue_potential'] = (df['rating_score'] * df['rating_count'] * df['price']) / 1000\n",
    "    \n",
    "    # Simple text features\n",
    "    df['title_length'] = df['title'].str.len()\n",
    "    df['description_length'] = df['description'].str.len()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create the business DataFrame\n",
    "enhanced_df = create_business_dataframe(large_dataset)\n",
    "\n",
    "if enhanced_df is not None:\n",
    "    print(f\"\\nEnhanced DataFrame created:\")\n",
    "    print(f\"  Shape: {enhanced_df.shape}\")\n",
    "    print(f\"  Columns: {list(enhanced_df.columns)}\")\n",
    "    \n",
    "    # Show performance distribution\n",
    "    print(f\"\\nPerformance categories:\")\n",
    "    perf_counts = enhanced_df['performance_category'].value_counts()\n",
    "    for category, count in perf_counts.items():\n",
    "        pct = (count / len(enhanced_df)) * 100\n",
    "        print(f\"  {category}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Show top value products\n",
    "    print(f\"\\nTop 5 value champions:\")\n",
    "    top_value = enhanced_df.nlargest(5, 'value_score')\n",
    "    for idx, row in top_value.iterrows():\n",
    "        print(f\"  {row['title'][:40]}... - ${row['price']:.2f} - {row['rating_score']}/5\")\n",
    "else:\n",
    "    print(\"Failed to create DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e01d95-6c86-41a8-9fae-881e06cb3af8",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Save Dataset\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd372790-d19b-49f4-9a0b-5679389bb333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving dataset...\n",
      "Raw data saved: data/raw/products_20250525_160043.json\n",
      "Processed data saved: data/processed/products_20250525_160043.csv\n",
      "Latest version: data/processed/products_latest.csv\n",
      "Summary saved: data/processed/summary_20250525_160043.txt\n",
      "\n",
      "Data collection complete!\n",
      "Ready for analysis with 2000 products\n"
     ]
    }
   ],
   "source": [
    "def save_dataset(products, dataframe):\n",
    "    \"\"\"Save both raw and processed data\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    try:\n",
    "        # Save raw JSON\n",
    "        raw_file = f'data/raw/products_{timestamp}.json'\n",
    "        with open(raw_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'products': products,\n",
    "                'metadata': {\n",
    "                    'timestamp': timestamp,\n",
    "                    'total_products': len(products),\n",
    "                    'generation_method': 'realistic_simulation'\n",
    "                }\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"Raw data saved: {raw_file}\")\n",
    "        \n",
    "        # Save processed CSV\n",
    "        if dataframe is not None:\n",
    "            csv_file = f'data/processed/products_{timestamp}.csv'\n",
    "            dataframe.to_csv(csv_file, index=False)\n",
    "            \n",
    "            # Also save as latest version\n",
    "            latest_file = 'data/processed/products_latest.csv'\n",
    "            dataframe.to_csv(latest_file, index=False)\n",
    "            \n",
    "            print(f\"Processed data saved: {csv_file}\")\n",
    "            print(f\"Latest version: {latest_file}\")\n",
    "            \n",
    "            # Create simple summary\n",
    "            summary_file = f'data/processed/summary_{timestamp}.txt'\n",
    "            with open(summary_file, 'w') as f:\n",
    "                f.write(\"E-COMMERCE DATASET SUMMARY\\n\")\n",
    "                f.write(\"=\" * 25 + \"\\n\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Total Products: {len(dataframe)}\\n\")\n",
    "                f.write(f\"Categories: {dataframe['category'].nunique()}\\n\")\n",
    "                f.write(f\"Price Range: ${dataframe['price'].min():.2f} - ${dataframe['price'].max():.2f}\\n\")\n",
    "                f.write(f\"Average Rating: {dataframe['rating_score'].mean():.2f}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Performance Distribution:\\n\")\n",
    "                for cat, count in dataframe['performance_category'].value_counts().items():\n",
    "                    pct = (count / len(dataframe)) * 100\n",
    "                    f.write(f\"  {cat}: {count} ({pct:.1f}%)\\n\")\n",
    "            \n",
    "            print(f\"Summary saved: {summary_file}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving files: {e}\")\n",
    "        return False\n",
    "\n",
    "# Save the dataset\n",
    "if large_dataset and enhanced_df is not None:\n",
    "    print(\"\\nSaving dataset...\")\n",
    "    success = save_dataset(large_dataset, enhanced_df)\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nData collection complete!\")\n",
    "        print(f\"Ready for analysis with {len(enhanced_df)} products\")\n",
    "    else:\n",
    "        print(\"Error saving dataset\")\n",
    "else:\n",
    "    print(\"No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b435d-6fb8-4168-be6c-b5d380f11144",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Dataset Validation & Preview\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9701152-f8e9-4522-adf5-f834fb644cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset validation:\n",
      "  ✓ No missing values\n",
      "  ✓ Data types look good\n",
      "  ✓ Price values valid\n",
      "  ✓ Rating values valid\n",
      "\n",
      "Dataset preview:\n",
      "                                               title     category    price  \\\n",
      "0  Apple Smartphones - Sharable bifurcated algorithm  electronics  1496.02   \n",
      "1       Dell Smartphones - Reactive explicit product  electronics   503.69   \n",
      "2   HP Headphones - Customizable systemic monitoring  electronics  1155.25   \n",
      "3     Bose Smartphones - Virtual national throughput  electronics   238.60   \n",
      "4  Samsung Headphones - Open-source maximized sup...  electronics  1126.48   \n",
      "\n",
      "   rating_score performance_category  \n",
      "0           4.9         Premium Star  \n",
      "1           4.4         Premium Star  \n",
      "2           3.9           Overpriced  \n",
      "3           4.8       Value Champion  \n",
      "4           5.0         Premium Star  \n",
      "\n",
      "Dataset ready for exploratory data analysis!\n"
     ]
    }
   ],
   "source": [
    "def validate_dataset(dataframe):\n",
    "    \"\"\"Quick validation and preview of the dataset\"\"\"\n",
    "    \n",
    "    if dataframe is None:\n",
    "        print(\"No dataframe to validate\")\n",
    "        return False\n",
    "    \n",
    "    print(\"Dataset validation:\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = dataframe.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"  Warning: Missing values found\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"  ✓ No missing values\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"  ✓ Data types look good\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    if dataframe['price'].min() < 0:\n",
    "        print(\"  Warning: Negative prices found\")\n",
    "    else:\n",
    "        print(\"  ✓ Price values valid\")\n",
    "    \n",
    "    if not (1 <= dataframe['rating_score'].min() and dataframe['rating_score'].max() <= 5):\n",
    "        print(\"  Warning: Ratings outside 1-5 range\")\n",
    "    else:\n",
    "        print(\"  ✓ Rating values valid\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nDataset preview:\")\n",
    "    print(dataframe[['title', 'category', 'price', 'rating_score', 'performance_category']].head())\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Validate the final dataset\n",
    "if enhanced_df is not None:\n",
    "    validate_dataset(enhanced_df)\n",
    "    print(f\"\\nDataset ready for exploratory data analysis!\")\n",
    "else:\n",
    "    print(\"No dataset to validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1ba8d-4484-4f30-b5e5-a5062420f5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
